# yandex-ml-compet-Nov2023
## Задание "Boosting"
В этом задании был реализован упрощенный вариант алгоритма бустинга для регрессии. Основой для бустинга послужили регрессионные модели, такие как деревья решений (DecisionTreeRegressor) и линейная регрессия (LinearRegression).
Алгоритм последовательно строит модели, каждая из которых фокусируется на ошибке предыдущей, уменьшая общую ошибку предсказания путем минимизации среднеквадратичной ошибки.

**Как реализовано:**

Реализация включает функции для вычисления потерь и градиентов потерь, что позволяет адаптировать веса моделей для улучшения предсказаний.
Бустинг использует динамическую корректировку целевых значений на основе градиентов потерь, оптимизируя процесс обучения.
Модели строятся итеративно с использованием заданного шага обучения и глубины для деревьев, что обеспечивает гибкость в настройке алгоритма под конкретные задачи.

**Освоено:**

1)Принципы и механизм работы бустинга, в том числе как последовательное обучение моделей может снижать общую ошибку предсказания.

2)Работа с градиентами потерь и их использование для корректировки целевых значений и весов моделей.

3)Практическое применение алгоритмов дерева решений и линейной регрессии в контексте бустинга.

## Задание "Bagging"
Разработан упрощенный вариант алгоритма бэггинга для регрессии. Бэггинг включает создание нескольких моделей, каждая из которых обучается на случайно выбранной подвыборке данных с возможностью повторения. 
Затем предсказания моделей усредняются для получения окончательного результата. Реализована также поддержка оценки "out-of-bag" (OOB) ошибки.

**Как реализовано:**

Разработан механизм для генерации подвыборок данных для каждой модели в ансамбле.
Использованы индивидуальные модели, обученные на этих подвыборках, для уменьшения вариативности и улучшения обобщающей способности.
Реализован расчет OOB ошибки, который позволяет оценить эффективность модели без необходимости кросс-валидации.

**Освоено:**

1)Основные принципы бэггинга, включая его способность уменьшать переобучение и повышать стабильность моделей.

2)Техники создания подвыборок и их влияние на эффективность ансамблевых методов.

3)Применение и вычисление OOB ошибки как метода оценки производительности ансамблевых моделей без отдельного тестового набора данных.

[Сертификат](https://certify.s3.yandex.net/young-yandex/c0eed431-76f4-4268-ab7d-5a96d42510aa/e6b19a65-11fd-461b-be5e-781ffdd5f36c.pdf?mindbox-message-key=-7998392931048161280&mindbox-click-id=f412b169-435b-4641-beb7-2034e920be90&utm_source=mindbox&utm_medium=email&utm_campaign=training4&utm_content=certificate)
